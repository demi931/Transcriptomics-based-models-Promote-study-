---
title: "Open Access For PROMOTE Study"
author: "Xiaoman"
date: "2024-01-21"
output:
  html_document: default
  pdf_document: default
---

# Input information
The parameters in this section will need to be set correctly for this script to work. *You will need to change it to fit your setup*.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggforce)
library(ggplot2)
# BiocManager::install("DESeq2")
library(DESeq2)
library(dplyr)
# BiocManager::install("ComplexHeatmap")
library(ComplexHeatmap)
library(tidyverse)
library(caret)
library(glmnet)

```
# Preparation
These tasks need to be done before the data analysis can begin.

# PCA (Location)


```{r}
expr_file <- "data/input/PROMOTE2samplechangeRR60samples(1).csv"

if (!file.exists(expr_file)) {
  stop("input file not found: ", expr_file)
}

# Read expression data
expr_raw <- read.csv(expr_file, row.names = 1, check.names = FALSE)

# Filter out genes with zero counts across all samples
expr_filtered <- expr_raw[rowSums(expr_raw) != 0, ]

# Transpose 
expr_matrix <- t(expr_filtered)

# PCA (exclude Location column)
pca_result <- prcomp(
  expr_matrix[, colnames(expr_matrix) != "Location"],
  scale. = TRUE
)

# Summary of PCA
summary(pca_result)

# PCA scores
pca_scores <- as.data.frame(pca_result$x[, 1:2])

# Add Location as a factor
pca_scores$Location <- as.factor(expr_matrix[, "Location"])

library(ggplot2)
library(ggforce)

ggplot(pca_scores, aes(x = PC1, y = PC2, colour = Location)) +
  geom_point(size = 3) +
  stat_ellipse(level = 0.9) +
  theme_classic()
```
  
  
# DESeq2 analysis
Let's normalize raw data and find difference genes by DESeq2.
```{r}
#Read and preprocess data and Filter out rows where the sum of values is not equal to zero
expr_file <- "data/input/PROMOTE2.csv"

if (!file.exists(expr_file)) {
  stop("input file not found: ", expr_file)
}
data <- read.csv(expr_file, row.names = 1, check.names = FALSE)
data2 <- data[rowSums(data) != 0,]



#Read the CSV file "PROMOTE2.1.csv" into a data frame, treating strings as factors

data1 <- read.csv("data/input/PROMOTE2.1.csv", stringsAsFactors = TRUE)

#Create a DESeqDataSet object from the count data and colData, designating the formula ~CBR
 
dds <- DESeqDataSetFromMatrix(countData = round(data2), colData = data1, design = ~CBR)

#Run DESeq on the DESeqDataSet
 
dds <- DESeq(dds)

#Extract results from DESeq analysis
 
res <- results(dds)

#Convert the DESeq results object to a data frame
 
res_1 <- data.frame(res)

#Display the first few rows of the results data frame
 
head(res_1)

#Mutate a new column 'group' based on log2FoldChange and adjusted p-value

res_1 %>%
  mutate(group = case_when(
    log2FoldChange >= 2 & padj <= 0.05 ~ "UP",
    log2FoldChange <= -2 & padj <= 0.05 ~ "DOWN",
    TRUE ~ "NOT_CHANGE"
  )) -> res_2

#Display the table of counts for each group in the 'group' column

table(res_2$group)

#Write the mutated data frame to a CSV file

write.csv(res_2, file = "diff_expr_result.csv", quote = FALSE)


```


# Visualize difference genes by Heatmap for CBR
We want to find if there is difference from CBR no response and response patients and visualize

```{r}

#mean value for each gene, then value of each sample divide mean value get "foldchangeJ" file

#Read data from the "foldchangeJ.csv" file, using the first column as row names

data <- read.csv("data/input/foldchangeJ.csv", row.names=1)

#Apply log2 transformation to the data and store it in log2J

log2(data + 1) -> log2J   

#Write the log-transformed data to a CSV file

write.csv(log2J, file="log2J.csv", row.names=TRUE)

#Read the log-transformed data from the "log2J.csv" file, using the first column as row names

expr_with_group <- read.csv(
  "log2J.csv",
  row.names = 1,
  check.names = FALSE
)

# Extract group information (sample-level annotation)
group_vec <- factor(
  as.character(unlist(expr_with_group["group", ])),
  levels = c("0", "1"),
  labels = c("No clinical benefit", "Clinical benefit")
)

# Remove group row to obtain expression matrix only
expr_matrix <- expr_with_group[rownames(expr_with_group) != "group", ]

# Convert to numeric matrix
expr_matrix <- data.matrix(expr_matrix)

# Build column annotation data frame
annotation_col <- data.frame(
  Group = group_vec
)

rownames(annotation_col) <- colnames(expr_matrix)

# Load required library
library(pheatmap)

# Draw heatmap (same package, same colors, grouping included)
heatmap_res <- pheatmap(
  expr_matrix,
  scale = "row",
  show_rownames = FALSE,
  cluster_col = FALSE,
  color = colorRampPalette(c("navy", "white", "firebrick3"))(100),
  annotation_col = annotation_col
)

# Output heatmap object
heatmap_res

```

              
# Visualize difference genes by Heatmap for RR
We want to find if there is difference from RR no response and response patients and visualize
```{r}
#Read data from the "RRfoldchangeJ.csv" file, using the first column as row names
data <- read.csv("data/input/RRfoldchangeJ.csv", row.names=1)

#Apply log2 transformation to the data and store it in log2J

log2(data + 1) -> log2J

#Write the log-transformed data to a CSV file

write.csv(log2J, file="log2JRR(1).csv", row.names=TRUE)

#Read the log-transformed data from the "log2JRR.csv" file, using the first column as row names

data <- read.csv("data/input/log2JRR(1).csv", row.names=1)

# Extract group information (sample annotation)
group_vec <- as.factor(unlist(data["group", ]))

# Remove group row from expression matrix
expr_mat <- data[rownames(data) != "group", ]

data1 <- data.matrix(expr_mat)

# Build annotation (sample-level)
annotation_c <- data.frame(
  Group = ifelse(group_vec == "1", "Response", "No response")
)

rownames(annotation_c) <- colnames(data1)

# Draw heatmap (same color, same package, grouping included)
B <- pheatmap(
  data1,
  scale = "row",
  show_rownames = FALSE,
  cluster_col = FALSE,
  color = colorRampPalette(c("navy", "white", "firebrick3"))(100),
  annotation_col = annotation_c
)
```

# PCA plot for CBR

Here we want to visualize difference from CBR no response and response patients

```{r}

#Read data from the "20260128stagepcacbr.csv" file, using the first column as row names

expr_with_meta <- read.csv(
  "20260128stagepcacbr.csv",
  row.names = 1,
  check.names = FALSE
)

# Extract sample annotations
Response_group <- factor(
  as.character(unlist(expr_with_meta["group", ])),
  levels = c("0", "1"),
  labels = c("No Clinical Benefit", "Clinical Benefit")
)

stage_group <- factor(
  as.character(unlist(expr_with_meta["stage", ])),
  levels = c("0", "1", "3", "4"),
  labels = c("Recurrence", "Stage1", "Stage3", "Stage4")
)

# Expression matrix only
expr_matrix <- expr_with_meta[!rownames(expr_with_meta) %in% c("group", "stage"), ]

# Remove genes with zero counts across samples
expr_matrix_filt <- expr_matrix[rowSums(expr_matrix) != 0, ]

# Transpose for PCA (samples × genes)
expr_matrix_t <- t(expr_matrix_filt)

# PCA
pca_result <- prcomp(expr_matrix_t, scale. = TRUE)
summary(pca_result)

# PCA scores
pca_scores <- as.data.frame(pca_result$x[, 1:2])
pca_scores$Response <- Response_group
pca_scores$Stage <- stage_group

# Plot PCA
library(ggplot2)

ggplot(
  pca_scores,
  aes(
    x = PC1,
    y = PC2,
    colour = Response_group,
    shape = Stage
  )
) +
  geom_point(size = 3) +
  theme_classic()

```

# PCA plot for RR

Here we want to visualize difference from RR no response and response patients

```{r}
#Read data from the "20260128stagepca(1).csv" file, using the first column as row names

data <- read.csv("data/input/20260128stagepca(1).csv", row.names=1)

# Extract sample annotations
group_vec <- as.factor(as.character(unlist(data["group", ])))
stage_vec <- as.factor(as.character(unlist(data["stage", ])))

expr_mat <- data[!rownames(data) %in% c("group", "stage"), ]
expr_mat <- expr_mat[rowSums(expr_mat) != 0, ]
data1 <- t(expr_mat)

pcdat <- prcomp(data1, scale. = TRUE)
summary(pcdat)
plotdat <- as.data.frame(pcdat$x[, 1:2])

# Add group (colour)
plotdat$Response <- factor(
  group_vec,
  levels = c("0", "1"),
  labels = c("No response", "Response")
)

# Add stage (shape)
plotdat$Stage <- factor(
  stage_vec,
  levels = c("0", "1", "3", "4"),
  labels = c("Recurrence", "Stage1", "Stage3", "Stage4")
)
library(ggplot2)
library(ggforce)

ggplot(
  plotdat,
  aes(
    x = PC1,
    y = PC2,
    colour = Response,
    shape = Stage
  )
) +
  geom_point(size = 3) +
  theme_classic()

# RFE for CBR
LR-RFEs were used to analyses data of gene and gene with clinical characters, to see how many variables we can select with optimal choose for CBR
```{r}
#Source custom functions from "importAllHandmadeFunctions.R"

source("CODE/importAllHandmadeFunctions.R")
#Define script locations
scriptsLocations <- paste(getwd(), "/scripts/", sep="")
#Import custom functions
importAllHandmadeFunctions(scriptsLocations)

```{r}

#Load readr library

library(readr)

#load function from machinelearning, dataExploration & modelPreprocessing created by Rianne
performLogitRfe = function(dataset, outcome, sizesPerIteration){
  library(caret)
  library(glmnet)
  if (missing(sizesPerIteration)){
    sizesPerIteration = c(2:dim(dataset)[2])
  }
  
  control <- rfeControl(functions = caretFuncs, method = "boot", verbose=T, returnResamp = "all")
  rfeProfile <- rfe(dataset, factor(outcome), rfeControl = control, method="glmnet", metric = "Accuracy", sizes = sizesPerIteration)
  print(plot(rfeProfile, type = c("g", "o")))
  return(rfeProfile)  
}

calculateVariableImportance = function(rfeProfile, meanOrMedian = "median"){
  variableInformation = rfeProfile$variables
  variableImportance = createEmptyDataFrame(length(unique(variableInformation$var)), 4)
  colnames(variableImportance) = c("name", "mean", "median", "std")
  variableImportance[,1] = unique(variableInformation$var)
  for (i in variableImportance$name){
    variableImportance[which(variableImportance$name == i),2] = mean(variableInformation$Overall[variableInformation$var == i])
    variableImportance[which(variableImportance$name == i),3] = median(variableInformation$Overall[variableInformation$var == i])
    variableImportance[which(variableImportance$name == i),4] = sd(variableInformation$Overall[variableInformation$var == i])
  }
  if (meanOrMedian == "mean"){
    p = createBarPlot(variableImportance$mean, variableImportance$name, "Mean variable importance")
  } else if (meanOrMedian == "median"){
    p = createBarPlot(variableImportance$median, variableImportance$name, "Median variable importance")
  }
  
  print(p)
  return(variableImportance)
  
}

performLogisticRegression = function(dataset, outcomeToTest, showSummary){
  logitModel = glm(factor(outcomeToTest)~., family=binomial(link='logit'), data = dataset)
  if (!missing(showSummary)){
    print(summary(logitModel))
  }
  return(logitModel)
}

createEmptyDataFrame = function(nrows, ncols, rowNames, columnNames){
  dataset = data.frame(matrix(ncol = ncols, nrow = nrows))
  if (!missing(columnNames)){
    colnames(dataset) = columnNames
  }
  if (!missing(rowNames)){
    row.names(dataset) = rowNames
  }
  return(dataset)
}

reduceVariablesLogit = function(trainingSet, outcomeData, variableImportance, meanOrMedian = "median"){
  library(pROC)
  
  if (meanOrMedian == "median"){
    variableImportance = variableImportance[order(variableImportance$median),]
  } else if (meanOrMedian == "mean"){
    variableImportance = variableImportance[order(variableImportance$mean),]
  }
  sortedDataset = trainingSet[,c(variableImportance$name)]
  allLogitModels = list()
  modelAuc = createEmptyDataFrame(dim(variableImportance)[1]-2, 5)
  colnames(modelAuc) = c("AUC", "sensitivity", "specificity", "overallAccuracy", "numberOfVariables")
  for (i in 1:(dim(variableImportance)[1]-2)){
    print(i)
    reducedDataset = sortedDataset[,(i+1):dim(sortedDataset)[2]]
    allLogitModels[[i]] = performLogisticRegression(reducedDataset, outcomeData)
    modelAuc[i,1] = auc(roc(outcomeData, predict(allLogitModels[[i]], type="response")))
    modelAuc[i,2] = calculateAccuracy(allLogitModels[[i]], outcomeData)[[1]]$sensitivity
    modelAuc[i,3] = calculateAccuracy(allLogitModels[[i]], outcomeData)[[1]]$specificity
    modelAuc[i,4] = calculateAccuracy(allLogitModels[[i]], outcomeData)[[1]]$overallAccuracy
    modelAuc[i,5] = dim(reducedDataset)[2]
  }
  return(list(allLogitModels, modelAuc))
}

calculateAccuracy = function(predictionModel, testSetOutcomes, testSet){
  # does not calculate AUC, but accuracy (TPR, TNR, FNR)
  confMatrix = createConfusionMatrix(predictionModel, testSetOutcomes, testSet)
  sensitivity = confMatrix[1,1] / (confMatrix[1,1] + confMatrix[2,1])
  specificity = confMatrix[2,2] / (confMatrix[1,2] + confMatrix[2,2])
  overallAccuracy = sum(confMatrix[1,1] + confMatrix[2,2]) / sum(confMatrix)
  return(list(
    data.frame("sensitivity" = sensitivity, "specificity" = specificity, "overallAccuracy" = overallAccuracy),
    confMatrix))
}

createConfusionMatrix = function(predictionModel, actualOutcomes, testSet){
  if (missing(testSet)){
    # predict onto trainingset
    modelPrediction = predict(predictionModel)
  } else {
    modelPrediction = predict(predictionModel, newdata = testSet)
  }
  if (predictionModel$method == "glmnet"){
    confMatrix = table(modelPrediction, actualOutcomes)
  } else if (predictionModel$method == "glm.fit"){
    confMatrix = table(ifelse(modelPrediction > 0.5, 2, 1), actualOutcomes)
  }
  if (dim(confMatrix)[1] != 2){
    confMatrix = rbind(confMatrix, c(0, 0))
  }
  return(confMatrix)
}

createROCCurve = function(predictionModel, outcomes, testSet){
  library(pROC)
  
  if (predictionModel$method == "glmnet"){
    if (missing(testSet)){
      outcomePrediction = predict(predictionModel, type = "prob")[1] # provides probabilities for both classes, but we only need one.
    } else {
      outcomePrediction = predict(predictionModel, type = "prob", newdata = testSet)[1] # provides probabilities for both classes, but we only need one.
    }
    rocObject = roc(outcomes, outcomePrediction[,1])
  } else if (predictionModel$method == "glm.fit"){
    if (missing(testSet)){
      outcomePrediction = predict(predictionModel) # provides probabilities for both classes, but we only need one.
    } else {
      outcomePrediction = predict(predictionModel, newdata = testSet) # provides probabilities for both classes, but we only need one.
    }
    rocObject = roc(outcomes, outcomePrediction)
  }
  
  
  plot(rocObject)
  text(0.2, 0.1, paste("AUC: ", round(auc(rocObject), 2)))
}

#load function

createBarPlot = function(numericList, xLabels, title = ""){
p = ggplot(data=as.data.frame(numericList), aes(x = xLabels, y=numericList)) +
  geom_bar(stat="identity") + ggtitle(title) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 45, hjust = 1))
return(p)
}


```



```{r}
#Read data from the "97genesCBRYN.csv" file, transpose, and create a data frame

#"97genesCBRYN.csv" file can be changed to "20251218selectedcbr+5clinic" or "20251212wholeCBR+5clinic" or "1211clinicmerge"

data <- read.csv("data/input/20251218selectedcbr+5clinic.csv", row.names=1)


#Define conditions and group labels

group <- as.numeric(data[1, ])

condition <- ifelse(group == 1, "CBR_responders", "CBR_non-responders")

#Create group data frame

df_group <- data.frame(group)

# Transpose the data
data<-data[-c(1),]

data <- as.data.frame(t(data))

#Set row names for the group data frame

rownames(df_group) <- rownames(data)

#Combine conditions and data for ordering

y_condition <- rbind(t(df_group), as.data.frame(t(data)))

y_ord_condition <- y_condition[, order(as.matrix(y_condition[1,]))]

y_ord <- y_ord_condition[-c(1),]

#Set seed for reproducibility

set.seed(1) 

#Sample random numbers for test and training sets (adjusted according to the number of Response and No Response in each file)

FiveRandomNumbers1 <- sort(sample.int(25, 8))

FiveRandomNumbers2 <- sort(sample(26:58, 8))

#Create test and training datasets

data_test <- y_ord[, cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

data_test <- as.data.frame(t(data_test))

condition_test <- condition[cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

condition_train <- condition[-cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

data_sample <- y_ord[, -cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

data_sample <- as.data.frame(t(data_sample))

condition_sample <- condition[-cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

#Perform Recursive Feature Elimination (RFE) for logistic regression

RFE_CBR <- performLogitRfe(data_sample, condition_sample, sizesPerIteration = seq(from=2, to=25, by=1))

# Plot RFE results

plot(RFE_CBR[["results"]][["Variables"]][1:24], RFE_CBR[["results"]][["Accuracy"]][1:24], type = "o", xlab="Variables", ylab = "Accuracy (Bootstrap)")

# Calculate variable importance and reduce variables

varImportance_CBR = calculateVariableImportance(RFE_CBR)

allLogitModels_CBR = reduceVariablesLogit(data_sample, condition_sample, varImportance_CBR)



#visualize first 20 variables

library(dplyr)
library(ggplot2)

varImportance_CBR <- calculateVariableImportance(RFE_CBR)

top20_vars <- varImportance_CBR %>%
  arrange(desc(median)) %>%
  head(20)

var_colname <- colnames(top20_vars)[1]

top20_vars[[var_colname]] <- factor(top20_vars[[var_colname]], levels = top20_vars[[var_colname]])

ggplot(top20_vars, aes_string(x = var_colname, y = "median")) +
  geom_col(fill = "steelblue") +
  labs(
    x = "Variable",
    y = "Median Importance",
    title = "Top 20 Variables by Median Importance (RFE)"
  ) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Plot AUC, sensitivity, specificity, and overall accuracy

{
  plot(rev(allLogitModels_CBR[[2]]$numberOfVariables)[1:35], rev(allLogitModels_CBR[[2]]$AUC)[1:35], ylim = c(0, 1), pch = 16)
  points(rev(allLogitModels_CBR[[2]]$numberOfVariables), rev(allLogitModels_CBR[[2]]$sensitivity), col = "red", pch = 16)
  points(rev(allLogitModels_CBR[[2]]$numberOfVariables), rev(allLogitModels_CBR[[2]]$specificity), col = "blue", pch = 16)
  points(rev(allLogitModels_CBR[[2]]$numberOfVariables), rev(allLogitModels_CBR[[2]]$overallAccuracy), col = "green", pch = 16)
  abline(v=7, col = "red")
  legend("bottomright", legend = c("AUC", "sensitivity", "specificity", "overall accuracy"), col = c("black", "red", "blue", "green"), pch = 16)
}

#Choose a model

chosenModel = 7

#Access the coefficients of the chosen model

glmProfileIndividual = allLogitModels_CBR[[1]][[dim(data_sample)[2] + 1 - chosenModel]]

saveRDS(glmProfileIndividual, paste(getwd(), "/rfeResults_CBR_condition_final.rds", sep = ""))

glmProfileIndividual = readRDS(paste(getwd(), "/rfeResults_CBR_condition_final.rds", sep= ""))

glmProfileIndividual$coefficients

#Calculate training accuracy and create ROC curve

trainingAccuracy = calculateAccuracy(glmProfileIndividual, condition_train)

createROCCurve(glmProfileIndividual, condition_train)

#Calculate test accuracy and create ROC curve

testAccuracy = calculateAccuracy(glmProfileIndividual, condition_test, data_test)

createROCCurve(glmProfileIndividual, condition_test, data_test)

```

# RFE for RR
LR-RFEs were used to analyses data of gene and gene with clinical characters, to see how many variables we can select with optimal choose for RR

```{r}

#Load readr library

library(readr)

#load function from machinelearning, dataExploration & modelPreprocessing created by Rianne
performLogitRfe = function(dataset, outcome, sizesPerIteration){
  library(caret)
  library(glmnet)
  if (missing(sizesPerIteration)){
    sizesPerIteration = c(2:dim(dataset)[2])
  }
  
  control <- rfeControl(functions = caretFuncs, method = "boot", verbose=T, returnResamp = "all")
  rfeProfile <- rfe(dataset, factor(outcome), rfeControl = control, method="glmnet", metric = "Accuracy", sizes = sizesPerIteration)
  print(plot(rfeProfile, type = c("g", "o")))
  return(rfeProfile)  
}

calculateVariableImportance = function(rfeProfile, meanOrMedian = "median"){
  variableInformation = rfeProfile$variables
  variableImportance = createEmptyDataFrame(length(unique(variableInformation$var)), 4)
  colnames(variableImportance) = c("name", "mean", "median", "std")
  variableImportance[,1] = unique(variableInformation$var)
  for (i in variableImportance$name){
    variableImportance[which(variableImportance$name == i),2] = mean(variableInformation$Overall[variableInformation$var == i])
    variableImportance[which(variableImportance$name == i),3] = median(variableInformation$Overall[variableInformation$var == i])
    variableImportance[which(variableImportance$name == i),4] = sd(variableInformation$Overall[variableInformation$var == i])
  }
  if (meanOrMedian == "mean"){
    p = createBarPlot(variableImportance$mean, variableImportance$name, "Mean variable importance")
  } else if (meanOrMedian == "median"){
    p = createBarPlot(variableImportance$median, variableImportance$name, "Median variable importance")
  }
  
  print(p)
  return(variableImportance)
  
}

performLogisticRegression = function(dataset, outcomeToTest, showSummary){
  logitModel = glm(factor(outcomeToTest)~., family=binomial(link='logit'), data = dataset)
  if (!missing(showSummary)){
    print(summary(logitModel))
  }
  return(logitModel)
}

createEmptyDataFrame = function(nrows, ncols, rowNames, columnNames){
  dataset = data.frame(matrix(ncol = ncols, nrow = nrows))
  if (!missing(columnNames)){
    colnames(dataset) = columnNames
  }
  if (!missing(rowNames)){
    row.names(dataset) = rowNames
  }
  return(dataset)
}

reduceVariablesLogit = function(trainingSet, outcomeData, variableImportance, meanOrMedian = "median"){
  library(pROC)
  
  if (meanOrMedian == "median"){
    variableImportance = variableImportance[order(variableImportance$median),]
  } else if (meanOrMedian == "mean"){
    variableImportance = variableImportance[order(variableImportance$mean),]
  }
  sortedDataset = trainingSet[,c(variableImportance$name)]
  allLogitModels = list()
  modelAuc = createEmptyDataFrame(dim(variableImportance)[1]-2, 5)
  colnames(modelAuc) = c("AUC", "sensitivity", "specificity", "overallAccuracy", "numberOfVariables")
  for (i in 1:(dim(variableImportance)[1]-2)){
    print(i)
    reducedDataset = sortedDataset[,(i+1):dim(sortedDataset)[2]]
    allLogitModels[[i]] = performLogisticRegression(reducedDataset, outcomeData)
    modelAuc[i,1] = auc(roc(outcomeData, predict(allLogitModels[[i]], type="response")))
    modelAuc[i,2] = calculateAccuracy(allLogitModels[[i]], outcomeData)[[1]]$sensitivity
    modelAuc[i,3] = calculateAccuracy(allLogitModels[[i]], outcomeData)[[1]]$specificity
    modelAuc[i,4] = calculateAccuracy(allLogitModels[[i]], outcomeData)[[1]]$overallAccuracy
    modelAuc[i,5] = dim(reducedDataset)[2]
  }
  return(list(allLogitModels, modelAuc))
}

calculateAccuracy = function(predictionModel, testSetOutcomes, testSet){
  # does not calculate AUC, but accuracy (TPR, TNR, FNR)
  confMatrix = createConfusionMatrix(predictionModel, testSetOutcomes, testSet)
  sensitivity = confMatrix[1,1] / (confMatrix[1,1] + confMatrix[2,1])
  specificity = confMatrix[2,2] / (confMatrix[1,2] + confMatrix[2,2])
  overallAccuracy = sum(confMatrix[1,1] + confMatrix[2,2]) / sum(confMatrix)
  return(list(
    data.frame("sensitivity" = sensitivity, "specificity" = specificity, "overallAccuracy" = overallAccuracy),
    confMatrix))
}

createConfusionMatrix = function(predictionModel, actualOutcomes, testSet){
  if (missing(testSet)){
    # predict onto trainingset
    modelPrediction = predict(predictionModel)
  } else {
    modelPrediction = predict(predictionModel, newdata = testSet)
  }
  if (predictionModel$method == "glmnet"){
    confMatrix = table(modelPrediction, actualOutcomes)
  } else if (predictionModel$method == "glm.fit"){
    confMatrix = table(ifelse(modelPrediction > 0.5, 2, 1), actualOutcomes)
  }
  if (dim(confMatrix)[1] != 2){
    confMatrix = rbind(confMatrix, c(0, 0))
  }
  return(confMatrix)
}

createROCCurve = function(predictionModel, outcomes, testSet){
  library(pROC)
  
  if (predictionModel$method == "glmnet"){
    if (missing(testSet)){
      outcomePrediction = predict(predictionModel, type = "prob")[1] # provides probabilities for both classes, but we only need one.
    } else {
      outcomePrediction = predict(predictionModel, type = "prob", newdata = testSet)[1] # provides probabilities for both classes, but we only need one.
    }
    rocObject = roc(outcomes, outcomePrediction[,1])
  } else if (predictionModel$method == "glm.fit"){
    if (missing(testSet)){
      outcomePrediction = predict(predictionModel) # provides probabilities for both classes, but we only need one.
    } else {
      outcomePrediction = predict(predictionModel, newdata = testSet) # provides probabilities for both classes, but we only need one.
    }
    rocObject = roc(outcomes, outcomePrediction)
  }
  
  
  plot(rocObject)
  text(0.2, 0.1, paste("AUC: ", round(auc(rocObject), 2)))
}

#load function

createBarPlot = function(numericList, xLabels, title = ""){
p = ggplot(data=as.data.frame(numericList), aes(x = xLabels, y=numericList)) +
  geom_bar(stat="identity") + ggtitle(title) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 45, hjust = 1))
return(p)
}


#Read data from "20251218selectedRR+5clinic.csv" file with row names

data <- read.csv("data/input/20251218selectedRR+5clinic.csv", row.names=1)

#"20251218selectedRR+5clinic.csv" can be changed to "103RRYN.csv","20251212wholeRR+5clinic","20251212mergeRR"

#Import custom functions

source("D:data/input/importAllHandmadeFunctions.R")

#Define script locations

scriptsLocations <- paste(getwd(), "scripts/")

#Import all custom functions

importAllHandmadeFunctions(scriptsLocations)

#Load ggplot2 library

library(ggplot2)

#Define conditions and group labels

group <- as.numeric(data[1, ])

condition <- ifelse(group == 1, "RR_responders", "RR_non-responders")

#Create group data frame

df_group <- data.frame(group)

# Transpose the data
data<-data[-c(1),]

data <- as.data.frame(t(data))


#Set row names for the group data frame

rownames(df_group) <- rownames(data)

#Combine conditions and data for sorting

y_condition <- rbind(t(df_group), as.data.frame(t(data)))

y_ord_condition <- y_condition[, order(as.matrix(y_condition[1,]))]

y_ord <- y_ord_condition[-c(1),]

#Set seed for reproducibility

set.seed(1)

#Generate two sets of random numbers (adjusted according to the number of Response and No Response in each file)

FiveRandomNumbers1 <- sort(sample.int(30, 8))

FiveRandomNumbers2 <- sort(sample(31:58, 8))

#Create test and training data sets

data_test <- y_ord[, cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

data_test <- as.data.frame(t(data_test))

condition_test <- condition[cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

condition_train <- condition[-cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

data_sample <- y_ord[, -cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

data_sample <- as.data.frame(t(data_sample))

condition_sample <- condition[-cbind(t(FiveRandomNumbers1), t(FiveRandomNumbers2))]

#Perform Recursive Feature Elimination (RFE) for logistic regression

RFE_RR <- performLogitRfe(data_sample, condition_sample, sizesPerIteration = seq(from=2, to=25, by=1)) 

# Plot RFE results
plot(RFE_RR[["results"]][["Variables"]][1:24], RFE_RR[["results"]][["Accuracy"]][1:24], type = "o", xlab="Variables", ylab = "Accuracy (Bootstrap)")

# Calculate variable importance and reduce variables for logistic regression
varImportance_RR = calculateVariableImportance(RFE_RR)
allLogitModels_RR = reduceVariablesLogit(data_sample, condition_sample, varImportance_RR)



#visualize first 20 variables


library(dplyr)
library(ggplot2)

# 1. 
varImportance_RR <- calculateVariableImportance(RFE_RR)

# 2. 
top20_vars <- varImportance_RR %>%
  arrange(desc(median)) %>%
  head(20)

# 3. 
var_colname <- colnames(top20_vars)[1]

top20_vars[[var_colname]] <- factor(top20_vars[[var_colname]],
                                    levels = top20_vars[[var_colname]])

# 4. 
ggplot(top20_vars, aes_string(x = var_colname, y = "median")) +
  geom_col(fill = "steelblue") +
  labs(
    x = "Variable",
    y = "Median Importance",
    title = "Top 20 Variables by Median Importance (RFE)"
  ) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Calculate variable importance and reduce variables for logistic regression
varImportance_RR = calculateVariableImportance(RFE_RR)
allLogitModels_RR = reduceVariablesLogit(data_sample, condition_sample, varImportance_RR)


# Plot AUC, sensitivity, specificity, and overall accuracy
{
  plot(rev(allLogitModels_RR[[2]]$numberOfVariables)[1:35], rev(allLogitModels_RR[[2]]$AUC)[1:35], ylim = c(0, 1), pch = 16)
  points(rev(allLogitModels_RR[[2]]$numberOfVariables), rev(allLogitModels_RR[[2]]$sensitivity), col = "red", pch = 16)
  points(rev(allLogitModels_RR[[2]]$numberOfVariables), rev(allLogitModels_RR[[2]]$specificity), col = "blue", pch = 16)
  points(rev(allLogitModels_RR[[2]]$numberOfVariables), rev(allLogitModels_RR[[2]]$overallAccuracy), col = "green", pch = 16)
  abline(v=7, col = "red")
  legend("bottomright", legend = c("AUC", "sensitivity", "specificity", "overall accuracy"), col = c("black", "red", "blue", "green"), pch = 16)
} 

#Choose a model
chosenModel = 8

#Get coefficients for the chosen model

glmProfileIndividual = allLogitModels_RR[[1]][[dim(data_sample)[2] + 1 - chosenModel]]

saveRDS(glmProfileIndividual, paste(getwd(), "/rfeResults_RR_condition_final.rds", sep = ""))

glmProfileIndividual = readRDS(paste(getwd(), "/rfeResults_RR_condition_final.rds", sep= ""))

glmProfileIndividual$coefficients

#Calculate training accuracy and create ROC curve

trainingAccuracy = calculateAccuracy(glmProfileIndividual, condition_train)

createROCCurve(glmProfileIndividual, condition_train)

#Calculate test accuracy and create ROC curve

testAccuracy = calculateAccuracy(glmProfileIndividual, condition_test, data_test)

createROCCurve(glmProfileIndividual, condition_test, data_test)

```


# dotplot (CBR and RR)
levels of the variables selected by the models to predict Response to treatment in EC patients
We use "5clinic+wholeDEGS" model as an example.
Extract selected features from the chosen logistic model (results of "glmProfileIndividual$coefficients")

```{r}

# dotplot

library(dplyr)
library(tidyr)
library(ggplot2)

# Continuous variables (selected features according to the model, can be changed by different models)
continuous_vars <- c(
  "ENSG00000127554","Age","ENSG00000134216",
  "ENSG00000198881","ENSG00000285854"
)

# Categorical variables (selected features according to the model, can be changed by different models)
categorical_vars <- c("FIGOstage","ERIHC_bi2","PRIHC_bi2","Grade")

# Prepare data for plotting
plot_df <- data %>%
  as.data.frame() %>%
  select(all_of(c(continuous_vars, categorical_vars))) %>%
  mutate(
    type = df_group$type,
    group_label = ifelse(type == 0, "No response", "Response")
  )

plot_df_long <- plot_df %>%
  pivot_longer(
    cols = all_of(c(continuous_vars, categorical_vars)),
    names_to = "variable",
    values_to = "value"
  )


# continuous-variable p-values (Wilcoxon) （not neccessary）
p_df <- plot_df_long %>%
  filter(variable %in% continuous_vars) %>%
  mutate(value = as.numeric(value)) %>%
  group_by(variable) %>%
  summarise(
    p = wilcox.test(value ~ group_label)$p.value,
    p_label = ifelse(p < 0.001, "P < 0.001", sprintf("P = %.3f", p)),
    .groups = "drop"
  )

# merge p-values back for plotting  （not neccessary）
plot_df_long <- plot_df_long %>%
  left_join(p_df %>% select(variable, p_label), by = "variable")

# plot
ggplot(plot_df_long, aes(x = group_label, y = value, color = group_label)) +
  geom_jitter(width = 0.15, size = 2, alpha = 0.7) +
  facet_wrap(~ variable, scales = "free_y") +
  labs(
    x = "Group",
    y = "Value",
    color = "Group",
    title = "Distribution of Predictors by Response Status"
  ) +
  theme_minimal(base_size = 14)

```
              

























